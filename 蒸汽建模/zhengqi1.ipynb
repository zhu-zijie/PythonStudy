{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 导入数据分析和可视化所需的库",
   "id": "4b0cb7d9e41a3952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 导入数据分析和可视化所需的库\n",
    "import numpy as np  # 用于数值计算\n",
    "import matplotlib.pyplot as plt  # 用于绘图\n",
    "import pandas as pd  # 用于数据处理\n",
    "import seaborn as sns  # 用于统计数据可视化\n",
    "import lightgbm as lgb  # 用于LightGBM模型\n",
    "from scipy import stats  # 用于统计分析\n",
    "from sklearn.model_selection import train_test_split  # 用于数据集划分\n",
    "from sklearn.metrics import mean_squared_error  # 用于均方误差计算\n",
    "from sklearn.linear_model import Ridge  # 用于岭回归\n",
    "from sklearn.linear_model import Lasso  # 用于Lasso回归\n",
    "from sklearn.svm import SVR  # 用于支持向量机回归\n",
    "from xgboost import XGBRegressor  # 用于XGBoost回归\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor  # 用于计算方差膨胀因子\n",
    "from sklearn.decomposition import PCA  # 用于主成分分析\n",
    "from sklearn.linear_model import LinearRegression  # 用于线性回归模型\n",
    "from sklearn.neighbors import KNeighborsRegressor  # 用于K近邻回归\n",
    "from sklearn.tree import DecisionTreeRegressor  # 用于决策树回归\n",
    "from sklearn.ensemble import RandomForestRegressor  # 用于随机森林回归\n",
    "from sklearn.ensemble import GradientBoostingRegressor  # 用于梯度提升回归\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')  # 忽略警告信息"
   ],
   "id": "e7e4d318f90aff8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 读取数据",
   "id": "1d0eb15b04ca816a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 定义数据文件路径\n",
    "train_data_file = '/Users/zhuzijie/Downloads/zhengqi/zhengqi_train.txt'\n",
    "test_data_file = '/Users/zhuzijie/Downloads/zhengqi/zhengqi_test.txt'\n",
    "# 读取训练和测试数据集（以制表符分隔）\n",
    "train_data = pd.read_csv(train_data_file, sep='\\t')\n",
    "test_data = pd.read_csv(test_data_file, sep='\\t')\n",
    "# 显示训练数据的统计摘要\n",
    "train_data.describe()"
   ],
   "id": "d9d433aa24fdf807"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 数据预处理",
   "id": "ca8fd0ba9905695a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 绘制箱线图",
   "id": "8fe353309455e9a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 为V0特征创建单独的箱线图\n",
    "fig_test = plt.figure(figsize=(12, 8))  # 设置图形大小\n",
    "sns.boxplot(x=train_data['V0'], width=0.5)  # 绘制箱线图，宽度为0.5\n",
    "plt.savefig('./2-特征箱式图.jpg', dpi=300)  # 保存图形为高分辨率图片"
   ],
   "id": "4ce6e5152de1b884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 为所有特征绘制箱线图\n",
    "# 获取所有特征（不包括目标变量）\n",
    "features = train_data.columns.tolist()[:38]  # 确保只包含38个特征\n",
    "num_features = len(features)\n",
    "\n",
    "# 计算布局\n",
    "n_cols = 3\n",
    "n_rows = (num_features + n_cols - 1) // n_cols  # 向上取整\n",
    "\n",
    "# 创建子图布局\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 2.5))\n",
    "axes = axes.flatten()  # 将二维数组展平为一维，便于索引\n",
    "\n",
    "# 设置全局标题\n",
    "fig.suptitle('各特征的分布情况（箱线图）', fontsize=16, y=0.92)\n",
    "\n",
    "# 设置字体\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "\n",
    "# 统一样式参数\n",
    "box_props = {\n",
    "    'boxprops': {'facecolor': '#1f77b4', 'edgecolor': 'black', 'alpha': 0.7},\n",
    "    'medianprops': {'color': 'red'},\n",
    "    'whiskerprops': {'color': 'black'},\n",
    "    'capprops': {'color': 'black'}\n",
    "}\n",
    "\n",
    "# 遍历每个特征绘制箱线图\n",
    "for i, feature in enumerate(features):\n",
    "    # 在当前子图上绘制箱线图\n",
    "    sns.boxplot(x=train_data[feature], ax=axes[i], width=0.6, **box_props)\n",
    "\n",
    "    # 添加网格线\n",
    "    axes[i].grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "    # 设置标题和轴标签\n",
    "    axes[i].set_title(feature, fontsize=10)\n",
    "    axes[i].set_xlabel('值', fontsize=8)\n",
    "    axes[i].set_ylabel('频率', fontsize=8)\n",
    "    axes[i].tick_params(axis='both', labelsize=7)\n",
    "\n",
    "# 隐藏多余的子图\n",
    "for i in range(num_features, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # 为标题留出空间\n",
    "\n",
    "# 保存高分辨率图片\n",
    "plt.savefig('./特征箱线图.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.close(fig)"
   ],
   "id": "2e2f0f585cda20a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 绘制特征分布对比图",
   "id": "5a3ec4ae0e300519"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建单特征分布对比图：训练集与测试集的V0特征\n",
    "# 创建图形和坐标轴\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 用来正常显示中文标签\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "\n",
    "# 定义一致的颜色方案\n",
    "train_color = '#E41A1C'  # 红色\n",
    "test_color = '#377EB8'  # 蓝色\n",
    "\n",
    "# 绘制核密度估计图\n",
    "sns.kdeplot(train_data['V0'], color=train_color, fill=True, alpha=0.8, ax=ax, label='训练集')\n",
    "sns.kdeplot(test_data['V0'], color=test_color, fill=True, alpha=0.8, ax=ax, label='测试集')\n",
    "\n",
    "# 设置图表标题和标签\n",
    "ax.set_title('V0特征的分布对比', fontsize=14, pad=10)\n",
    "ax.set_xlabel('V0值', fontsize=12)\n",
    "ax.set_ylabel('密度', fontsize=12)\n",
    "\n",
    "# 添加图例\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "# 优化刻度标签大小\n",
    "ax.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "# 添加网格线提高可读性\n",
    "ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存高分辨率图片\n",
    "plt.savefig('./V0特征分布对比.jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n",
    "\n",
    "plt.close(fig)"
   ],
   "id": "57805352f7ca5472"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建多个子图比较训练集和测试集的特征分布\n",
    "# 计算布局参数\n",
    "dist_cols = 6\n",
    "dist_rows = (len(test_data.columns) + dist_cols - 1) // dist_cols  # 向上取整确保空间足够\n",
    "\n",
    "# 创建图形和轴对象数组\n",
    "fig, axes = plt.subplots(dist_rows, dist_cols, figsize=(4 * dist_cols, 3.5 * dist_rows))\n",
    "axes = axes.flatten()  # 将二维数组展平为一维，便于索引\n",
    "\n",
    "# 用来正常显示中文标签\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "\n",
    "# 设置全局标题\n",
    "fig.suptitle('特征分布对比: 训练集 vs 测试集', fontsize=16, y=0.92)\n",
    "\n",
    "# 定义一致的颜色和样式\n",
    "train_color = '#E41A1C'  # 红色\n",
    "test_color = '#377EB8'  # 蓝色\n",
    "\n",
    "# 遍历所有特征\n",
    "for i, col in enumerate(test_data.columns):\n",
    "    # 在当前子图上绘制核密度估计\n",
    "    sns.kdeplot(train_data[col], color=train_color, fill=True, alpha=0.8, ax=axes[i], label='训练集')\n",
    "    sns.kdeplot(test_data[col], color=test_color, fill=True, alpha=0.8, ax=axes[i], label='测试集')\n",
    "\n",
    "    # 设置轴标签\n",
    "    axes[i].set_xlabel(col, fontsize=10)\n",
    "    axes[i].set_ylabel('密度', fontsize=10)\n",
    "    axes[i].legend(fontsize=8)\n",
    "    axes[i].tick_params(axis='both', labelsize=8)  # 调整刻度标签大小\n",
    "\n",
    "# 隐藏多余的子图\n",
    "for i in range(len(test_data.columns), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "# 调整子图之间的间距\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)  # 为标题留出空间\n",
    "\n",
    "# 保存高分辨率图片\n",
    "plt.savefig('./特征分布对比.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ],
   "id": "6cfcee0ad616868"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 特征相关性分析",
   "id": "93e7a7cbf67a2e9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 特征变量相关性\n",
    "drop_col_kde = ['V5', 'V9', 'V11', 'V17', 'V22', 'V28']\n",
    "train_data_drop = train_data.drop(columns=drop_col_kde)\n",
    "train_corr = train_data_drop.corr()\n",
    "train_corr"
   ],
   "id": "b4b0ab941aff9bf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制热力图显示特征之间的相关性\n",
    "fig, ax = plt.subplots(figsize=(20, 16))  # 创建一个大尺寸的图形(20x20英寸)以容纳所有相关性数据\n",
    "sns.heatmap(train_corr, vmax=.8, square=True, annot=True, ax=ax)  # 绘制相关性热力图，设置最大颜色值为0.8，使用方形单元格，并在每个单元格中显示具体的相关系数值"
   ],
   "id": "7ca938f77e5c69ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建优化的相关性热力图（下三角矩阵）\n",
    "plt.figure(figsize=(20, 16), clear=True)\n",
    "\n",
    "# 计算相关性矩阵\n",
    "corr_matrix = train_data_drop.corr()\n",
    "\n",
    "# 创建掩码以仅显示下三角矩阵，避免信息重复\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# 创建更美观的颜色映射\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)  # 蓝-白-红配色方案\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "\n",
    "# 绘制热力图\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmin=-1,  # 设置颜色范围\n",
    "    vmax=1,\n",
    "    center=0,  # 将白色设为0值\n",
    "    square=True,  # 确保单元格为正方形\n",
    "    annot=True,  # 显示相关系数\n",
    "    fmt='.2f',  # 保留两位小数\n",
    "    linewidths=0.5,  # 设置网格线宽度\n",
    "    cbar_kws={'shrink': 0.8, 'label': '相关系数'}  # 自定义颜色条\n",
    ")\n",
    "\n",
    "# 设置标题\n",
    "plt.title('特征相关性分析热力图', fontsize=16, pad=10)\n",
    "\n",
    "# 优化布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存高分辨率图片\n",
    "plt.savefig('./特征相关性分析.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ],
   "id": "87e5980c4890f6e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 特征删除",
   "id": "29e30ebcc18f7bc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 根据数据分布进行特征删除\n",
    "train_data.drop(drop_col_kde, axis=1, inplace=True)\n",
    "test_data.drop(drop_col_kde, axis=1, inplace=True)\n",
    "train_data.head()"
   ],
   "id": "cba33e3ce5e51734"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 根据相关性系数进行特征筛选\n",
    "cond = corr_matrix['target'].abs() < 0.1\n",
    "drop_col_corr = corr_matrix.index[cond]\n",
    "train_data.drop(drop_col_corr, axis=1, inplace=True)\n",
    "test_data.drop(drop_col_corr, axis=1, inplace=True)\n",
    "train_data.head()"
   ],
   "id": "3bd86e043afe2cb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 数据整合",
   "id": "aaa3214bcff0b6ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 整合训练数据和测试数据\n",
    "train_data['label'] = 'train'\n",
    "test_data['label'] = 'test'\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "all_data.to_csv('./processed_zhengqi_data.csv', index=False)"
   ],
   "id": "4857488857ac08ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 特征归一化",
   "id": "7e84b05bfb03a496"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 特征归一化\n",
    "columns = list(all_data.columns)\n",
    "# 删除标签列索引\n",
    "columns.remove('label')\n",
    "# 删除目标值\n",
    "columns.remove('target')\n",
    "all_data[columns].head()"
   ],
   "id": "f8e69e851629ca80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 定义归一化\n",
    "def norm_min_max(data):\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "\n",
    "all_data[columns] = all_data[columns].apply(norm_min_max, axis=0)\n",
    "all_data.describe()"
   ],
   "id": "7e0b83661f44cb9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 特征分布分析",
   "id": "744c62a4d8212915"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 获取训练数据\n",
    "cond = all_data['label'] == 'train'\n",
    "train_data = all_data[cond]\n",
    "train_data.drop(labels='label', axis=1, inplace=True)"
   ],
   "id": "b60d30c80729a90c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建一个宽20英寸、高8英寸的图形画布\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# 第一部分：绘制特征V0的分布直方图\n",
    "ax1 = plt.subplot(1, 3, 1)  # 创建1行3列的子图布局，选择第1个位置\n",
    "sns.histplot(data=train_data, x='V0', kde=True, stat='density', ax=ax1)  # 绘制V0的直方图，并叠加核密度估计曲线\n",
    "# 添加正态分布曲线\n",
    "x = np.linspace(train_data['V0'].min(), train_data['V0'].max(), 100)  # 创建从V0最小值到最大值的100个等间距点\n",
    "y = stats.norm.pdf(x, train_data['V0'].mean(), train_data['V0'].std())  # 计算这些点对应的正态分布概率密度值\n",
    "# 绘制正态分布拟合曲线，并进行缩放以匹配直方图高度\n",
    "ax1.plot(x, y, color='red', lw=2)\n",
    "ax1.set_title('V0分布图')  # 设置子图标题\n",
    "\n",
    "# 第二部分：绘制Q-Q图(Quantile-Quantile plot)检验数据是否符合正态分布\n",
    "ax2 = plt.subplot(1, 3, 2)  # 选择第2个子图位置\n",
    "valid_data = train_data['V0'].dropna()  # 去除V0中可能的缺失值\n",
    "stats.probplot(valid_data, plot=ax2)  # 绘制Q-Q图，比较数据分位数与理论正态分布分位数\n",
    "ax2.set_title(f'skew={stats.skew(valid_data):.4f}')  # 显示偏度值，判断分布偏离正态的程度\n",
    "\n",
    "# 第三部分：绘制特征V0与目标变量target的散点图，分析相关性\n",
    "ax3 = plt.subplot(1, 3, 3)  # 选择第3个子图位置\n",
    "ax3.scatter(train_data['V0'], train_data['target'], s=5, alpha=0.5)  # 绘制散点图，点大小为5，透明度为0.5\n",
    "corr = np.corrcoef(train_data['V0'].values, train_data['target'].values)[0, 1]  # 计算皮尔逊相关系数\n",
    "ax3.set_title(f'corr={corr:.4f}')  # 在子图标题中显示相关系数，保留4位小数\n",
    "\n",
    "plt.tight_layout()  # 自动调整子图参数，使之填充整个图像区域且子图之间不重叠\n",
    "plt.savefig('./6-Box-Cox.jpg', dpi=300, bbox_inches='tight')  # 保存高分辨率图像，确保边界紧凑\n",
    "plt.show()  # 显示图形"
   ],
   "id": "a9063d19afc99300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cols = 3  # 每行的子图数量\n",
    "columns = list(train_data.columns)\n",
    "columns.remove('target')\n",
    "rows = len(columns)  # 特征数量\n",
    "plt.figure(figsize=(5 * cols, 4 * rows))  # 创建一个宽15英寸、高4乘以特征数量英寸的图形画布\n",
    "\n",
    "for i, feature in enumerate(columns):\n",
    "    row_position = i * cols + 1  # 计算当前特征在图中的起始位置\n",
    "\n",
    "    # 第一部分：绘制特征的分布直方图\n",
    "    ax1 = plt.subplot(rows, cols, row_position)\n",
    "    sns.histplot(data=train_data, x=feature, kde=True, stat='density', ax=ax1)\n",
    "    # 添加正态分布曲线\n",
    "    x = np.linspace(train_data[feature].min(), train_data[feature].max(), 100)\n",
    "    y = stats.norm.pdf(x, train_data[feature].mean(), train_data[feature].std())\n",
    "    # 绘制正态分布曲线，无需缩放因为使用了stat='density'\n",
    "    ax1.plot(x, y, color='red', lw=2)\n",
    "    ax1.set_title(f'{feature}分布图')\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_ylabel('')\n",
    "\n",
    "    # 第二部分：绘制Q-Q图\n",
    "    ax2 = plt.subplot(rows, cols, row_position + 1)\n",
    "    valid_data = train_data[feature].dropna()\n",
    "    stats.probplot(valid_data, plot=ax2)\n",
    "    ax2.set_title(f'skew={stats.skew(valid_data):.4f}')\n",
    "    ax2.set_xlabel('')\n",
    "    ax2.set_ylabel('')\n",
    "\n",
    "    # 第三部分：绘制特征与目标变量target的散点图\n",
    "    ax3 = plt.subplot(rows, cols, row_position + 2)\n",
    "    ax3.scatter(train_data[feature], train_data['target'], s=5, alpha=0.5)\n",
    "    corr = np.corrcoef(train_data[feature].values, train_data['target'].values)[0, 1]\n",
    "    ax3.set_title(f'corr={corr:.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./features_analysis.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "cd19e50189277395"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Box-Cox变换",
   "id": "1271308c5989df3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Box-Cox变换\n",
    "cols = 6  # 每行的子图数量\n",
    "columns = list(train_data.columns)\n",
    "columns.remove('target')\n",
    "rows = len(columns)  # 特征数量\n",
    "plt.figure(figsize=(5 * cols, 4 * rows))\n",
    "\n",
    "\n",
    "def norm_min_max(data):\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "\n",
    "for i, feature in enumerate(columns):\n",
    "    row_position = i * cols + 1\n",
    "\n",
    "    # 第一部分：绘制特征的原始分布直方图\n",
    "    ax1 = plt.subplot(rows, cols, row_position)\n",
    "    sns.histplot(data=train_data, x=feature, kde=True, stat='density', ax=ax1)\n",
    "    x = np.linspace(train_data[feature].min(), train_data[feature].max(), 100)\n",
    "    y = stats.norm.pdf(x, train_data[feature].mean(), train_data[feature].std())\n",
    "    ax1.plot(x, y, color='red', lw=2)\n",
    "    ax1.set_title(f'{feature}分布图-raw')\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_ylabel('')\n",
    "\n",
    "    # 第二部分：绘制原始特征Q-Q图\n",
    "    ax2 = plt.subplot(rows, cols, row_position + 1)\n",
    "    valid_data = train_data[feature].dropna()\n",
    "    stats.probplot(valid_data, plot=ax2)\n",
    "    ax2.set_title(f'skew={stats.skew(valid_data):.4f}-raw')\n",
    "    ax2.set_xlabel('')\n",
    "    ax2.set_ylabel('')\n",
    "\n",
    "    # 第三部分：绘制原始特征与目标变量的散点图\n",
    "    ax3 = plt.subplot(rows, cols, row_position + 2)\n",
    "    ax3.scatter(train_data[feature], train_data['target'], s=5, alpha=0.5)\n",
    "    corr = np.corrcoef(train_data[feature].values, train_data['target'].values)[0, 1]\n",
    "    ax3.set_title(f'corr={corr:.2f}-raw')\n",
    "\n",
    "    # Box-Cox变换（确保数据为正值）\n",
    "    feature_data = train_data[feature].dropna()\n",
    "    if feature_data.min() <= 0:\n",
    "        feature_data = feature_data - feature_data.min() + 1  # 确保全部为正值\n",
    "\n",
    "    # 应用Box-Cox变换\n",
    "    transformed_data, lambda_val = stats.boxcox(feature_data)\n",
    "\n",
    "    # 归一化变换后的数据\n",
    "    transformed_norm = norm_min_max(transformed_data)\n",
    "\n",
    "    # 第四部分：变换后的分布直方图\n",
    "    ax4 = plt.subplot(rows, cols, row_position + 3)\n",
    "    sns.histplot(transformed_norm, kde=True, stat='density', ax=ax4)\n",
    "    x_trans = np.linspace(min(transformed_norm), max(transformed_norm), 100)\n",
    "    y_trans = stats.norm.pdf(x_trans, np.mean(transformed_norm), np.std(transformed_norm))\n",
    "    ax4.plot(x_trans, y_trans, color='red', lw=2)\n",
    "    ax4.set_title(f'{feature}分布图-Box-Cox')\n",
    "    ax4.set_xlabel('')\n",
    "    ax4.set_ylabel('')\n",
    "\n",
    "    # 第五部分：变换后的Q-Q图\n",
    "    ax5 = plt.subplot(rows, cols, row_position + 4)\n",
    "    stats.probplot(transformed_norm, plot=ax5)\n",
    "    ax5.set_title(f'skew={stats.skew(transformed_norm):.4f}-Box-Cox')\n",
    "    ax5.set_xlabel('')\n",
    "    ax5.set_ylabel('')\n",
    "\n",
    "    # 第六部分：变换后的特征与目标变量的散点图\n",
    "    ax6 = plt.subplot(rows, cols, row_position + 5)\n",
    "    # 获取对应的目标变量值\n",
    "    target_values = train_data.loc[feature_data.index, 'target'].values\n",
    "    ax6.scatter(transformed_norm, target_values, s=5, alpha=0.5)\n",
    "    corr_trans = np.corrcoef(transformed_norm, target_values)[0, 1]\n",
    "    ax6.set_title(f'corr={corr_trans:.2f}-Box-Cox')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./features_Box_Cox_analysis.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "4cb271c0ab91ca72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "columns = list(all_data.columns)\n",
    "# 删除标签列索引\n",
    "columns.remove('label')\n",
    "# 删除目标值\n",
    "columns.remove('target')\n",
    "\n",
    "for col in columns:\n",
    "    all_data[col], lambda_val = stats.boxcox(all_data[col] + 1)"
   ],
   "id": "b71183fcdbe83b4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 模型训练",
   "id": "6815f315b9a7b988"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 数据集划分",
   "id": "758709bf6c483be3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_train_data(data=None):\n",
    "    \"\"\"\n",
    "    获取训练数据集的特征和目标变量\n",
    "\n",
    "    参数:\n",
    "    data - 数据集DataFrame，如果为None则使用全局的all_data变量\n",
    "\n",
    "    返回:\n",
    "    X - 特征矩阵\n",
    "    y - 目标变量\n",
    "    \"\"\"\n",
    "    # 如果未提供数据，则使用全局变量\n",
    "    if data is None:\n",
    "        data = all_data\n",
    "\n",
    "    # 筛选出训练数据\n",
    "    train_data = data[data['label'] == 'train']\n",
    "    # 提取目标变量\n",
    "    y = train_data['target']\n",
    "    # 提取特征变量（排除目标变量和标签列）\n",
    "    X = train_data.drop(['target', 'label'], axis=1)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def split_train_test(test_size=0.2, random_state=42, data=None):\n",
    "    \"\"\"\n",
    "    将训练数据集拆分为训练集和验证集\n",
    "\n",
    "    参数:\n",
    "    test_size - 验证集比例，默认为0.2（20%）\n",
    "    random_state - 随机数种子，用于确保结果可重复，默认为42\n",
    "    data - 数据集DataFrame，如果为None则使用全局的all_data变量\n",
    "\n",
    "    返回:\n",
    "    X_train - 训练集特征\n",
    "    X_valid - 验证集特征\n",
    "    y_train - 训练集目标变量\n",
    "    y_valid - 验证集目标变量\n",
    "    \"\"\"\n",
    "    # 获取训练数据\n",
    "    X, y = get_train_data(data)\n",
    "\n",
    "    # 使用sklearn的train_test_split函数进行数据集拆分\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "def get_test_data(data=None):\n",
    "    \"\"\"\n",
    "    获取测试数据集的特征\n",
    "\n",
    "    参数:\n",
    "    data - 数据集DataFrame，如果为None则使用全局的all_data变量\n",
    "\n",
    "    返回:\n",
    "    X_test - 测试集特征\n",
    "    \"\"\"\n",
    "    # 如果未提供数据，则使用全局变量\n",
    "    if data is None:\n",
    "        data = all_data\n",
    "\n",
    "    # 筛选出测试数据并重置索引\n",
    "    test_data = data[data['label'] == 'test'].reset_index(drop=True)\n",
    "    # 提取特征变量（排除标签列，测试集可能没有目标列）\n",
    "    drop_cols = ['label']\n",
    "    if 'target' in test_data.columns:\n",
    "        drop_cols.append('target')\n",
    "    X_test = test_data.drop(drop_cols, axis=1)\n",
    "\n",
    "    return X_test"
   ],
   "id": "a9b3675785e33f6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 异常值检测",
   "id": "f5db6c6e9f6a7066"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_outliers(model, X, y, sigma=3):\n",
    "    \"\"\"\n",
    "    使用回归模型检测数据集中的异常值\n",
    "\n",
    "    参数:\n",
    "    model - 回归模型对象（如Ridge, Lasso等）\n",
    "    X - 特征数据\n",
    "    y - 目标变量\n",
    "    sigma - 标准差阈值，超过此值被视为异常值\n",
    "\n",
    "    返回:\n",
    "    outliers - 异常值的索引\n",
    "    \"\"\"\n",
    "    # 模型训练\n",
    "    model.fit(X, y)\n",
    "    y_pred = pd.Series(model.predict(X), index=y.index)  # 预测值，保持与原始数据相同的索引\n",
    "\n",
    "    # 计算残差（真实值与预测值之差）\n",
    "    resid = y - y_pred\n",
    "    mean_resid = resid.mean()  # 残差均值\n",
    "    std_resid = resid.std()  # 残差标准差\n",
    "\n",
    "    # 异常值计算：将残差标准化为Z分数\n",
    "    z = (resid - mean_resid) / std_resid\n",
    "    outliers = z[abs(z) > sigma].index  # Z分数超过sigma倍标准差的视为异常值\n",
    "\n",
    "    # 输出模型评价指标\n",
    "    print('R2=', model.score(X, y))  # 决定系数\n",
    "    print(\"mse=\", mean_squared_error(y, y_pred))  # 均方误差\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    # 输出残差统计信息\n",
    "    print('残差均值:', mean_resid)\n",
    "    print('残差标准差:', std_resid)\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    # 输出异常值信息\n",
    "    print(f'发现{len(outliers)}个异常值:')\n",
    "    print(outliers.to_list())\n",
    "\n",
    "    # 创建可视化图表\n",
    "    plt.figure(figsize=(24, 8))\n",
    "\n",
    "    # 子图1：真实值与预测值的散点图\n",
    "    ax131 = plt.subplot(1, 3, 1)\n",
    "    ax131.scatter(y, y_pred, marker='.', alpha=0.7)  # 绘制所有样本点\n",
    "    ax131.scatter(y.loc[outliers], y_pred[outliers], color='red', marker='o')  # 突出显示异常值\n",
    "    ax131.legend(['正常样本', '异常值'])\n",
    "    ax131.set_xlabel('真实值')\n",
    "    ax131.set_ylabel('预测值')\n",
    "    ax131.grid(True, linestyle='--', alpha=0.3)  # 添加网格线\n",
    "\n",
    "    # 子图2：真实值与残差的散点图\n",
    "    ax132 = plt.subplot(1, 3, 2)\n",
    "    ax132.scatter(y, y - y_pred, marker='.', alpha=0.7)  # 绘制所有样本点\n",
    "    ax132.scatter(y.loc[outliers], y.loc[outliers] - y_pred[outliers], color='red', marker='o')  # 突出显示异常值\n",
    "    ax132.legend(['正常样本', '异常值'])\n",
    "    ax132.set_xlabel('真实值')\n",
    "    ax132.set_ylabel('残差')\n",
    "    ax132.grid(True, linestyle='--', alpha=0.3)  # 添加网格线\n",
    "    ax132.axhline(y=0, color='k', linestyle='-', alpha=0.3)  # 添加y=0的参考线\n",
    "\n",
    "    # 子图3：残差Z分数直方图\n",
    "    ax133 = plt.subplot(1, 3, 3)\n",
    "    # 绘制正常样本的Z分数直方图\n",
    "    ax133.hist(z[~z.index.isin(outliers)], bins=50, alpha=0.7)\n",
    "    # 绘制异常值的Z分数直方图\n",
    "    ax133.hist(z.loc[outliers], bins=50, color='red', alpha=0.7)\n",
    "    ax133.legend(['正常样本', '异常值'])\n",
    "    ax133.set_xlabel('Z分数')\n",
    "    ax133.set_ylabel('频数')\n",
    "    ax133.grid(True, linestyle='--', alpha=0.3)  # 添加网格线\n",
    "\n",
    "    # 添加异常值阈值参考线\n",
    "    ax133.axvline(x=sigma, color='r', linestyle='--', alpha=0.5)\n",
    "    ax133.axvline(x=-sigma, color='r', linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./outliers_hist.jpg', dpi=300, bbox_inches='tight')\n",
    "    return outliers"
   ],
   "id": "a8e149718b68abd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 岭回归算法查找异常值\n",
    "# 获取训练数据\n",
    "X_train, y_train = get_train_data()\n",
    "# 使用岭回归查找异常值\n",
    "outliers1 = find_outliers(Ridge(), X_train, y_train)"
   ],
   "id": "977dd64588529dc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 套索回归算法查找异常值\n",
    "# 获取训练数据\n",
    "X_train, y_train = get_train_data()\n",
    "# 使用Lasso查找异常值\n",
    "outliers2 = find_outliers(Lasso(), X_train, y_train)"
   ],
   "id": "c60095be8c4f4dbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 支持向量机SVR算法查找异常值\n",
    "# 获取训练数据\n",
    "X_train, y_train = get_train_data()\n",
    "# 使用SVR查找异常值\n",
    "outliers3 = find_outliers(SVR(), X_train, y_train)"
   ],
   "id": "d9ad57bb0a6951e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Xgboost算法查找异常值\n",
    "# 获取训练数据\n",
    "X_train, y_train = get_train_data()\n",
    "# 使用Xgboost查找异常值\n",
    "outliers4 = find_outliers(XGBRegressor(), X_train, y_train)"
   ],
   "id": "44a8e4e123f066e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 联合所有检测到的异常值\n",
    "all_outliers = list(set(list(outliers1) + list(outliers2) + list(outliers3) + list(outliers4)))\n",
    "print(f\"Ridge回归检测到 {len(outliers1)} 个异常值\")\n",
    "print(f\"Lasso回归检测到 {len(outliers2)} 个异常值\")\n",
    "print(f\"SVR检测到 {len(outliers3)} 个异常值\")\n",
    "print(f\"XGBoost检测到 {len(outliers4)} 个异常值\")\n",
    "print(f\"合并后共有 {len(all_outliers)} 个唯一异常值\")\n",
    "\n",
    "# 创建一个布尔掩码：保留测试数据以及不在异常值列表中的训练数据\n",
    "keep_mask = ~((all_data['label'] == 'train') & all_data.index.isin(all_outliers))\n",
    "\n",
    "# 应用掩码筛选数据\n",
    "all_data_clean = all_data[keep_mask]\n",
    "\n",
    "# 保存处理后的数据\n",
    "all_data_clean.to_csv('./processed_zhengqi_data.csv', index=False)\n",
    "print(f\"原始数据形状: {all_data.shape}\")\n",
    "print(f\"清洗后数据形状: {all_data_clean.shape}\")\n",
    "print(f\"已删除 {all_data.shape[0] - all_data_clean.shape[0]} 行异常数据\")"
   ],
   "id": "7c6458e837ded93a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### VIF分析",
   "id": "4be00576691dff8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# VIF计算代码\n",
    "def calculate_vif(df):\n",
    "    \"\"\"\n",
    "    计算数据框中所有特征的方差膨胀因子(VIF)\n",
    "\n",
    "    参数:\n",
    "    df - 包含特征变量的DataFrame\n",
    "\n",
    "    返回:\n",
    "    vif_df - 包含每个特征VIF值的DataFrame\n",
    "    \"\"\"\n",
    "    # 创建包含特征名和VIF值的DataFrame\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "\n",
    "    # 计算每个特征的VIF值\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "\n",
    "    # 排序显示结果\n",
    "    return vif_data.sort_values(\"VIF\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 获取训练数据\n",
    "X_train, y_train = get_train_data(all_data_clean)\n",
    "\n",
    "# 计算并显示VIF值\n",
    "vif_results = calculate_vif(X_train)\n",
    "print(\"方差膨胀因子(VIF)分析结果:\")\n",
    "display(vif_results)"
   ],
   "id": "16ef7a515b70ed00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### PCA降维",
   "id": "4278b7da9dec70e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# PCA降维\n",
    "def perform_pca_analysis(X, n_components=22):\n",
    "    \"\"\"\n",
    "    执行PCA降维分析并计算降维后的VIF值\n",
    "\n",
    "    参数:\n",
    "    X - 输入特征矩阵\n",
    "    n_components - PCA组件数量\n",
    "    plot_variance - 是否绘制解释方差图，默认True\n",
    "\n",
    "    返回:\n",
    "    X_pca - 降维后的特征矩阵\n",
    "    pca_model - 训练好的PCA模型\n",
    "    \"\"\"\n",
    "    # 1. 创建PCA模型\n",
    "    # whiten=True: 白化处理，使各主成分具有相同的方差\n",
    "    pca = PCA(n_components=n_components, whiten=True)\n",
    "\n",
    "    # 2. 拟合模型并转换数据\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    # 3. 分析并展示PCA结果\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "    print(f\"使用{n_components}个主成分，共解释了{cumulative_variance[-1] * 100:.2f}%的总方差\")\n",
    "\n",
    "    return X_pca, pca\n",
    "\n",
    "\n",
    "# 计算降维后的VIF值\n",
    "def calculate_vif_after_pca(X_pca):\n",
    "    \"\"\"\n",
    "    计算PCA降维后各主成分的方差膨胀因子(VIF)\n",
    "\n",
    "    参数:\n",
    "    X_pca - PCA降维后的数据\n",
    "\n",
    "    返回:\n",
    "    vif_df - 包含VIF值的DataFrame\n",
    "    \"\"\"\n",
    "    # 创建包含主成分编号和VIF值的DataFrame\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"主成分\"] = [f\"PC{i + 1}\" for i in range(X_pca.shape[1])]\n",
    "\n",
    "    # 计算每个主成分的VIF值\n",
    "    vif_values = [variance_inflation_factor(X_pca, i) for i in range(X_pca.shape[1])]\n",
    "    vif_data[\"VIF\"] = [round(val, 2) for val in vif_values]  # 四舍五入到两位小数\n",
    "\n",
    "    return vif_data\n",
    "\n",
    "\n",
    "# 获取训练数据\n",
    "X_train, y_train = get_train_data(all_data_clean)\n",
    "# 执行PCA分析\n",
    "X_train_pca, pca_model = perform_pca_analysis(X_train, n_components=22)\n",
    "# 计算并显示降维后的VIF值\n",
    "vif_results = calculate_vif_after_pca(X_train_pca)\n",
    "print(\"PCA降维后主成分的VIF值分析:\")\n",
    "display(vif_results)\n",
    "\n",
    "# 保存降维后的数据\n",
    "np.savez('./train_data_pca', X_train=X_train_pca, y_train=y_train.values)\n",
    "\n",
    "print(f\"PCA降维结果已保存。原始特征维度: {X_train.shape[1]}, 降维后维度: {X_train_pca.shape[1]}\")"
   ],
   "id": "c85c75267d01c666"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_test = get_test_data(all_data_clean)\n",
    "X_test_pca = pca_model.transform(X_test)\n",
    "np.savez('./test_data_pca', X_test=X_test_pca)"
   ],
   "id": "f6a62abf0bd0f6c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 采用pca降维后的数据进行建模\n",
    "train_data = np.load('./train_data_pca.npz')['X_train']\n",
    "target_data = np.load('./train_data_pca.npz')['y_train']\n",
    "# 切分数据\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, target_data, test_size=0.2)"
   ],
   "id": "82b995ba49d4e73f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 多元线性回归模型",
   "id": "f2be94501054e5ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 多元线性回归模型\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "score = mean_squared_error(y_valid, clf.predict(X_valid))\n",
    "print(\"LinearRegression均方误差:\", score)"
   ],
   "id": "8d69db9ddb2aadd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 训练数据验证数据评估可视化\n",
    "def plot_learning_curve(model, X_train, X_valid, y_train, y_valid):\n",
    "    \"\"\"\n",
    "    绘制学习曲线，展示训练集和验证集的性能随训练样本数量的变化\n",
    "\n",
    "    参数:\n",
    "    model - 机器学习模型\n",
    "    X_train - 训练集特征\n",
    "    X_valid - 验证集特征\n",
    "    y_train - 训练集目标变量\n",
    "    y_valid - 验证集目标变量\n",
    "    \"\"\"\n",
    "\n",
    "    # 初始化存储训练和验证分数的列表\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    for i in range(10, len(X_train) + 1, 10):\n",
    "        model.fit(X_train[:i], y_train[:i])\n",
    "        # 训练数据评估\n",
    "        y_train_pred = model.predict(X_train[:i])\n",
    "        train_scores.append(mean_squared_error(y_train[:i], y_train_pred))\n",
    "\n",
    "        # 验证数据评估\n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        valid_scores.append(mean_squared_error(y_valid, y_valid_pred))\n",
    "\n",
    "    # 可视化\n",
    "    plt.plot([i for i in range(1, len(train_scores) + 1, 1)], train_scores, label='训练集')\n",
    "    plt.plot([i for i in range(1, len(valid_scores) + 1, 1)], valid_scores, label='验证集')\n",
    "    plt.legend()"
   ],
   "id": "fb9fcc80ebfa05d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_learning_curve(LinearRegression(), X_train, X_valid, y_train, y_valid)\n",
    "plt.savefig('./learning_curve.png', dpi=300, bbox_inches='tight')"
   ],
   "id": "c2c8548f37414a0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### K近邻回归模型",
   "id": "bb6f53fcb5521aae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# K近邻回归模型\n",
    "for i in range(3, 20):\n",
    "    clf = KNeighborsRegressor(n_neighbors=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = mean_squared_error(y_valid, clf.predict(X_valid))\n",
    "    print(f\"KNeighbors<UNK>{i}<UNK>: {score}\")"
   ],
   "id": "e9974952bf58e5cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 决策树回归模型",
   "id": "cabd5d8bcedf9046"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 决策树回归\n",
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "score = mean_squared_error(y_valid, clf.predict(X_valid))\n",
    "print(\"DecisionTreeRegressor均方误差:\", score)"
   ],
   "id": "22ec9557213d613b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 随机森林回归模型",
   "id": "76953cda72f58bc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 随机森林回归模型\n",
    "clf = RandomForestRegressor(\n",
    "    n_estimators=200,  # 设置森林中决策树的数量为200棵，增加模型稳定性和精度\n",
    "    max_depth=10,  # 限制树的最大深度为10，防止过拟合\n",
    "    min_samples_leaf=10,  # 每个叶节点最少包含10个样本，增强泛化能力\n",
    "    min_samples_split=40,  # 分裂内部节点所需的最小样本数为40，控制树的生长\n",
    "    max_features='sqrt',  # 每次分裂时考虑的特征数量为特征总数的平方根，增加模型多样性\n",
    "    criterion='squared_error'  # 使用均方误差作为分裂质量的衡量标准\n",
    ")\n",
    "\n",
    "# 使用训练集拟合模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测并计算均方误差(MSE)评估模型性能\n",
    "# 均方误差越小表示模型预测越准确\n",
    "score = mean_squared_error(y_valid, clf.predict(X_valid))\n",
    "\n",
    "# 输出模型在验证集上的均方误差\n",
    "print(\"RandomForestRegressor均方误差:\", score)"
   ],
   "id": "d0520dd7db47b2ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 随机森林回归模型评估可视化\n",
    "plot_learning_curve(clf, X_train, X_valid, y_train, y_valid)"
   ],
   "id": "492002c6682de5de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 向量机回归模型",
   "id": "617181fd03e52348"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 支持向量回归(SVR)模型训练与评估\n",
    "# 创建第一个SVR模型实例 - 使用径向基函数(RBF)/高斯核\n",
    "clf1 = SVR(\n",
    "    kernel='rbf',  # 使用高斯径向基核函数，适合非线性数据建模\n",
    "    C=1.0,  # 正则化参数，控制对误差的容忍度，值越小正则化越强\n",
    "    gamma=0.01,  # 核函数系数，定义每个训练样本的影响范围，较小值意味着影响范围大\n",
    "    tol=0.0001,  # 停止训练的误差阈值，提高精度但可能增加训练时间\n",
    "    epsilon=0.3  # 不计入损失函数的误差带宽，调整模型对噪声的敏感度\n",
    ")\n",
    "\n",
    "# 使用训练数据拟合第一个SVR模型\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测并计算均方误差，评估高斯核SVR性能\n",
    "score = mean_squared_error(y_valid, clf1.predict(X_valid))\n",
    "\n",
    "# 输出高斯核SVR模型的均方误差评估结果\n",
    "print(\"支持向量机高斯核函数均方误差:\", score)\n",
    "\n",
    "# 创建第二个SVR模型实例 - 使用多项式核函数\n",
    "clf2 = SVR(\n",
    "    kernel='poly',  # 使用多项式核函数\n",
    "    C=1.0,  # 正则化参数，控制模型复杂度与拟合质量的平衡\n",
    "    degree=3,  # 多项式核函数的次数，影响模型的复杂度\n",
    "    coef0=1.0,  # 核函数中的独立项系数，影响高阶项与低阶项的权重\n",
    "    gamma='scale',  # 核函数系数，scale表示1/(n_features*X.var())\n",
    "    epsilon=0.1,  # 不敏感区域宽度，小于epsilon的误差不会被考虑\n",
    "    tol=0.0001  # 停止训练的误差阈值\n",
    ")\n",
    "\n",
    "# 使用训练数据拟合第二个SVR模型\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测并计算均方误差，评估多项式核SVR性能\n",
    "score = mean_squared_error(y_valid, clf2.predict(X_valid))\n",
    "\n",
    "# 输出多项式核SVR模型的均方误差评估结果\n",
    "print(\"支持向量机多项式核函数均方误差:\", score)"
   ],
   "id": "190e1305930d7a99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 支持向量机SVR模型评估可视化\n",
    "plot_learning_curve(clf1, X_train, X_valid, y_train, y_valid)"
   ],
   "id": "2a337fb574510ed9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### LightGBM梯度提升回归模型",
   "id": "2f0b38fcbc370cd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# LightGBM梯度提升回归模型\n",
    "clf = lgb.LGBMRegressor(\n",
    "    learning_rate=0.1,  # 学习率：控制每次迭代对模型的调整幅度，较高的值加快学习但可能导致过拟合\n",
    "    n_estimators=500,  # 树的数量：设置为500棵，增加模型复杂度和学习能力\n",
    "    max_depth=8,  # 树的最大深度：限制为5层以防止过拟合\n",
    "    num_leaves=50,  # 叶子节点最大数量：控制树的复杂度，值越大模型越复杂\n",
    "    min_child_samples=5,  # 叶子节点最小样本数：每个叶节点至少需要10个样本，提高稳定性\n",
    "    subsample=0.8,  # 样本采样比例：每棵树随机使用80%的训练样本，减少过拟合风险\n",
    "    colsample_bytree=0.8,  # 特征采样比例：每棵树随机使用80%的特征，增加模型多样性\n",
    "    reg_alpha=0.1,  # L1正则化系数：控制模型稀疏性，有助于特征选择\n",
    "    reg_lambda=0.05  # L2正则化系数：降低模型复杂度，防止过拟合\n",
    ")\n",
    "\n",
    "# 使用训练数据拟合LightGBM模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上评估模型性能，计算均方误差\n",
    "score = mean_squared_error(y_valid, clf.predict(X_valid))\n",
    "\n",
    "# 输出模型在验证集上的均方误差\n",
    "print(\"LGBMRegressor均方误差:\", score)"
   ],
   "id": "e706a125cdc5a3ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### GBR梯度提升回归模型",
   "id": "2429f42be21f7718"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 梯度提升回归(GBR)模型\n",
    "clf = GradientBoostingRegressor(\n",
    "    learning_rate=0.03,  # 学习率：控制每棵树对最终预测的贡献度，值较小可提高模型稳定性\n",
    "    loss='huber',  # 损失函数：使用Huber损失，对异常值更具鲁棒性，平衡了均方误差和绝对误差的特点\n",
    "    max_depth=14,  # 树的最大深度：限制为14层，增强模型复杂度和拟合能力\n",
    "    max_features='sqrt',  # 特征选择方式：每次分裂时随机考虑特征总数的平方根，增加模型泛化能力\n",
    "    min_samples_leaf=10,  # 叶节点最小样本数：每个叶节点至少需要10个样本，避免过拟合\n",
    "    min_samples_split=40,  # 分裂节点所需最小样本数：内部节点分裂至少需要40个样本，控制树的生长\n",
    "    n_estimators=300,  # 弱学习器(树)的数量：设置为300棵，通过集成多个模型提升预测精度\n",
    "    subsample=0.8  # 样本采样比例：每棵树随机使用80%的训练样本，降低过拟合风险\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "score = mean_squared_error(y_valid, clf.predict(X_valid))\n",
    "print(\"GradientBoosting均方误差:\", score)"
   ],
   "id": "13ebe749aace4e5"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
